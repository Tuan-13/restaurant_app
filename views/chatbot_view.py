# views/chatbot_view.py
import streamlit as st
import time
from google import genai
from google.genai import types
from utils.translate import get_text

# --- T·ªêI ∆ØU H√ìA: Cache Client ---
# Gi√∫p kh√¥ng ph·∫£i kh·ªüi t·∫°o l·∫°i k·∫øt n·ªëi m·ªói khi ng∆∞·ªùi d√πng t∆∞∆°ng t√°c, l√†m app m∆∞·ª£t h∆°n.
@st.cache_resource
def get_genai_client(api_key):
    return genai.Client(api_key=api_key)

def render_chatbot_tab(lang):
    # L·∫•y tr·∫°ng th√°i dark mode
    is_dark = st.session_state.get("dark_mode", False)

    # 1. Giao di·ªán Header hi·ªán ƒë·∫°i
    st.markdown(f"""
    <div style="
        background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
        padding: 1.5rem 2rem;
        border-radius: 16px;
        margin-bottom: 1.5rem;
        box-shadow: 0 4px 15px rgba(102, 126, 234, 0.3);
    ">
        <div style="display: flex; align-items: center; justify-content: space-between;">
            <div>
                <div style="
                    font-family: 'Poppins', sans-serif;
                    font-size: 1.5rem;
                    font-weight: 600;
                    color: white;
                    display: flex;
                    align-items: center;
                    gap: 0.75rem;
                ">
                    <span style="font-size: 1.75rem;">ü§ñ</span>
                    {get_text('chatbot_title', lang)}
                </div>
                <div style="
                    color: rgba(255,255,255,0.8);
                    font-size: 0.9rem;
                    margin-top: 0.25rem;
                ">{get_text('chatbot_caption', lang)}</div>
            </div>
        </div>
    </div>
    """, unsafe_allow_html=True)

    # N√∫t x√≥a chat
    col_spacer, col_btn = st.columns([4, 1])
    with col_btn:
        if st.button(get_text("clear_chat", lang), use_container_width=True):
            st.session_state.gemini_messages = []
            st.rerun()

    # 2. Kh·ªüi t·∫°o Client
    # L·∫•y API Key t·ª´ secrets (b·∫£o m·∫≠t h∆°n hardcode)
    api_key = st.secrets.get("GOOGLE_AI_API_KEY")
    
    if api_key:
        client = get_genai_client(api_key)
    else:
        st.warning(get_text("no_api_key", lang))
        client = None

    # Rate limit state (per-session simple limiter)
    # Limits provided by user: RPM=10, RPD=20
    RPM = 10
    RPD = 20
    now = int(time.time())
    minute_window = now // 60
    day_window = now // 86400

    if 'chat_rate' not in st.session_state:
        st.session_state['chat_rate'] = {
            'minute_window': minute_window,
            'minute_count': 0,
            'day_window': day_window,
            'day_count': 0
        }

    def check_rate_limit():
        rs = st.session_state['chat_rate']
        # minute reset
        if rs['minute_window'] != minute_window:
            rs['minute_window'] = minute_window
            rs['minute_count'] = 0
        if rs['day_window'] != day_window:
            rs['day_window'] = day_window
            rs['day_count'] = 0

        if rs['minute_count'] >= RPM:
            return False, f"Quota v∆∞·ª£t qu√°: ch·ªâ cho ph√©p {RPM} y√™u c·∫ßu/ph√∫t. Vui l√≤ng ch·ªù v√†i gi√¢y."
        if rs['day_count'] >= RPD:
            return False, f"Quota ng√†y ƒë√£ ƒë·∫ßy: ch·ªâ cho ph√©p {RPD} y√™u c·∫ßu/ng√†y. H√£y th·ª≠ l·∫°i ng√†y mai."

        # increment counters (will assume request proceeds)
        rs['minute_count'] += 1
        rs['day_count'] += 1
        return True, None

    # 3. Chu·∫©n b·ªã Context (D·ªØ li·ªáu qu√°n ƒÉn)
    # Logic: Ch·ªâ l·∫•y Top 5 qu√°n ƒë·ªÉ ƒë∆∞a v√†o ng·ªØ c·∫£nh -> Ti·∫øt ki·ªám Token ƒë·∫ßu v√†o
    search_context = ""
    if "search_results" in st.session_state and st.session_state.search_results:
        top_results = st.session_state.search_results[:15] 
        search_context = "\n\n[D·ªÆ LI·ªÜU T√åM KI·∫æM T·ª™ B·∫¢N ƒê·ªí]:\n"
        for i, r in enumerate(top_results):
            # L√†m tr√≤n kho·∫£ng c√°ch
            dist = int(r.get('distance_sort', 0))
            # Format ng·∫Øn g·ªçn: T√™n | Gi√° | Lo·∫°i | C√°ch xa
            search_context += f"{i+1}. {r['name']} | Gi√°: {r['price']} | Lo·∫°i: {r['cuisine']} | C√°ch: {dist}m\n"
    else:
        search_context = "\n(Ng∆∞·ªùi d√πng ch∆∞a t√¨m ki·∫øm qu√°n n√†o tr√™n b·∫£n ƒë·ªì)."

    # 4. X√¢y d·ª±ng System Prompt (H∆∞·ªõng d·∫´n h√†nh vi)
    # Ch√∫ng ta g·ªôp h∆∞·ªõng d·∫´n h√†nh vi v√†o m·ªôt "system-like" message ƒë·ªÉ model hi·ªÉu b·ªëi c·∫£nh.
    system_prompt_text = f"""
    ROLE: B·∫°n l√† "Foodie Guide" - m·ªôt tr·ª£ l√Ω ·∫©m th·ª±c ƒë·ªãa ph∆∞∆°ng chuy√™n nghi·ªáp, th√¢n thi·ªán, hi·ªÉu vƒÉn h√≥a ·∫©m th·ª±c Vi·ªát Nam.
    CONTEXT: {search_context}

    INSTRUCTIONS (H√ÄNH VI):
    1) ∆Øu ti√™n d·ªØ li·ªáu t·ª´ CONTEXT n·∫øu c√≥: khi ng∆∞·ªùi d√πng h·ªèi v·ªÅ qu√°n trong danh s√°ch, h√£y tr√≠ch d·∫´n t√™n, kho·∫£ng c√°ch, ∆∞·ªõc l∆∞·ª£ng th·ªùi gian, v√† ∆∞u/nh∆∞·ª£c ƒëi·ªÉm.
    2) N·∫øu c√¢u h·ªèi kh√¥ng r√µ r√†ng, ƒë·∫∑t t·ªëi ƒëa 2 c√¢u h·ªèi l√†m r√µ.
    3) Tr·∫£ l·ªùi chi ti·∫øt, c√≥ c·∫•u tr√∫c: m·ªü ƒë·∫ßu ng·∫Øn (1-2 c√¢u), ph·∫ßn ch√≠nh d∆∞·ªõi d·∫°ng bullet/pairs (∆∞u nh∆∞·ª£c/so s√°nh), ph·∫ßn k·∫øt l√† khuy·∫øn ngh·ªã v√† h√†nh ƒë·ªông ti·∫øp theo.
    4) Cung c·∫•p m·ªôt d√≤ng "T√≥m t·∫Øt:" ng·∫Øn g·ªçn ·ªü ƒë·∫ßu, v√† ƒë·ªÅ xu·∫•t 2 ph∆∞∆°ng √°n ti·∫øp theo (v√≠ d·ª•: g·ªçi, ƒë·∫øn tr·ª±c ti·∫øp, xem b·∫£n ƒë·ªì).
    5) Ng√¥n ng·ªØ tr·∫£ l·ªùi: theo `lang` (n·∫øu `vi` th√¨ ti·∫øng Vi·ªát). D√πng emoji v·ª´a ph·∫£i ƒë·ªÉ l√†m r√µ.
    6) Kh√¥ng xu·∫•t API keys, th√¥ng tin nh·∫°y c·∫£m; n·∫øu c·∫ßn API key ƒë·ªÉ h√†nh ƒë·ªông, h∆∞·ªõng d·∫´n ng∆∞·ªùi d√πng c√°ch c·∫•u h√¨nh `.streamlit/secrets.toml`.
    7) Khi tr·∫£ l·ªùi, n·∫øu c√≥ th·ªÉ, th√™m `ESTIMATED_DISTANCE` v√† `ESTIMATED_TRAVEL_TIME` d·ª±a tr√™n context (m n·∫øu <1000, km n·∫øu >1000) v√† ∆∞·ªõc l∆∞·ª£ng ph√∫t.

    FORMAT INSTRUCTION:
    - B·∫Øt ƒë·∫ßu b·∫±ng m·ªôt d√≤ng "T√≥m t·∫Øt:"
    - D√πng ti√™u ƒë·ªÅ/ƒëo·∫°n ng·∫Øn + bullet points
    - K·∫øt th√∫c b·∫±ng: "G·ª£i √Ω ti·∫øp theo:" v·ªõi 2 l·ª±a ch·ªçn h√†nh ƒë·ªông.
    """

    # 5. Giao di·ªán Suggestion Chips (G·ª£i √Ω c√¢u h·ªèi)
    # Ch·ªâ hi·ªán khi ch∆∞a c√≥ l·ªãch s·ª≠ chat
    prompt = None
    if "gemini_messages" not in st.session_state:
        st.session_state["gemini_messages"] = []

    if not st.session_state.gemini_messages:
        # Suggestion header v·ªõi thi·∫øt k·∫ø m·ªõi - h·ªó tr·ª£ dark mode
        suggestion_bg = "linear-gradient(135deg, #1e293b 0%, #334155 100%)" if is_dark else "linear-gradient(135deg, #f0f9ff 0%, #e0f2fe 100%)"
        suggestion_border = "#475569" if is_dark else "#bae6fd"
        suggestion_title_color = "#60a5fa" if is_dark else "#0369a1"
        suggestion_text_color = "#94a3b8" if is_dark else "#64748b"

        st.markdown(f"""
        <div style="
            background: {suggestion_bg};
            border: 1px solid {suggestion_border};
            border-radius: 12px;
            padding: 1rem 1.25rem;
            margin-bottom: 1rem;
        ">
            <div style="
                font-weight: 600;
                color: {suggestion_title_color};
                margin-bottom: 0.5rem;
                display: flex;
                align-items: center;
                gap: 0.5rem;
            ">
                <span>üí°</span> {get_text("suggestion_header", lang)}
            </div>
            <div style="color: {suggestion_text_color}; font-size: 0.85rem;">
                {get_text('suggestion_hint', lang)}
            </div>
        </div>
        """, unsafe_allow_html=True)

        # Chips v·ªõi thi·∫øt k·∫ø ƒë·∫πp h∆°n
        cols = st.columns(3)
        if cols[0].button(f"üìä {get_text('chip_analyze', lang)}", use_container_width=True):
            prompt = "D·ª±a tr√™n danh s√°ch c√°c qu√°n t√¨m ƒë∆∞·ª£c, h√£y ph√¢n t√≠ch ∆∞u nh∆∞·ª£c ƒëi·ªÉm c·ªßa ch√∫ng."
        if cols[1].button(f"üç¥ {get_text('chip_side_dish', lang)}", use_container_width=True):
            dish = st.session_state.get('dish_input', 'm√≥n n√†y')
            prompt = f"M√≥n {dish} th∆∞·ªùng ƒÉn k√®m v·ªõi g√¨ cho ƒë√∫ng ƒëi·ªáu?"
        if cols[2].button(f"üí∞ {get_text('chip_cheapest', lang)}", use_container_width=True):
            prompt = "Qu√°n n√†o r·∫ª nh·∫•t v√† g·∫ßn nh·∫•t trong danh s√°ch?"

    # 6. Hi·ªÉn th·ªã L·ªãch s·ª≠ Chat (UI)
    for message in st.session_state.gemini_messages:
        role = "user" if message.role == "user" else "assistant"
        # Tr√≠ch xu·∫•t text an to√†n t·ª´ object Content
        if hasattr(message, 'parts') and len(message.parts) > 0:
            content = message.parts[0].text
        else:
            content = str(message)
            
        with st.chat_message(role):
            st.markdown(content)

    # 7. X·ª≠ l√Ω Input ng∆∞·ªùi d√πng
    user_input = st.chat_input(get_text("chat_placeholder", lang))
    final_prompt = prompt if prompt else user_input

    # 8. Logic G·ª≠i tin nh·∫Øn & G·ªçi API
    if final_prompt:
        if not client:
            st.error(get_text('please_config_api', lang))
            return

        # A. Hi·ªÉn th·ªã & L∆∞u tin nh·∫Øn User
        with st.chat_message("user"):
            st.markdown(final_prompt)
        
        user_msg_obj = types.Content(role="user", parts=[types.Part(text=final_prompt)])
        st.session_state.gemini_messages.append(user_msg_obj)

        # B. X·ª≠ l√Ω Chatbot ph·∫£n h·ªìi
        with st.chat_message("assistant"):
            message_placeholder = st.empty()
            full_response = ""
            
            try:
                # --- K·ª∏ THU·∫¨T TI·∫æT KI·ªÜM QUOTA & S·ª¨A L·ªñI 400 ---
                
                # B1. T·∫°o tin nh·∫Øn System gi·∫£ (ƒë√≥ng vai tr√≤ l√† User message ƒë·∫ßu ti√™n)
                # ƒê√¢y l√† c√°ch ƒë·ªÉ Gemma hi·ªÉu ng·ªØ c·∫£nh m√† kh√¥ng c·∫ßn tham s·ªë system_instruction
                sys_msg = types.Content(role="user", parts=[types.Part(text=system_prompt_text)])
                
                # B2. L·∫•y l·ªãch s·ª≠ chat (tr·ª´ tin nh·∫Øn m·ªõi nh·∫•t v·ª´a append ƒë·ªÉ tr√°nh tr√πng l·∫∑p khi gh√©p)
                history = st.session_state.gemini_messages[:-1]
                
                # B3. Sliding Window: Ch·ªâ l·∫•y 6 tin nh·∫Øn g·∫ßn nh·∫•t ƒë·ªÉ g·ª≠i ƒëi
                # Gi√∫p gi·∫£m s·ªë l∆∞·ª£ng token input, ph·∫£n h·ªìi nhanh h∆°n v√† ti·∫øt ki·ªám quota
                if len(history) > 6:
                    history = history[-6:]
                
                # B4. Gh√©p th√†nh danh s√°ch g·ª≠i API: [Lu·∫≠t ch∆°i] + [L·ªãch s·ª≠ ng·∫Øn] + [C√¢u h·ªèi m·ªõi]
                messages_to_send = [sys_msg] + history + [user_msg_obj]

                # B5. Ki·ªÉm tra rate limit tr∆∞·ªõc khi g·ªçi API
                allowed, reason = check_rate_limit()
                if not allowed:
                    message_placeholder.error(reason)
                    return

                # B6. G·ªçi API Streaming v·ªõi model y√™u c·∫ßu
                response = client.models.generate_content_stream(
                    model="gemini-2.5-flash-lite",
                    contents=messages_to_send,
                    config=types.GenerateContentConfig(
                        temperature=0.3,
                        max_output_tokens=800,
                    )
                )

                # Stream k·∫øt qu·∫£ v·ªÅ UI
                for chunk in response:
                    # M·ªôt s·ªë chunk c√≥ c·∫•u tr√∫c kh√°c nhau; l·∫•y text an to√†n
                    text = getattr(chunk, 'text', None)
                    if not text and hasattr(chunk, 'delta'):
                        text = getattr(chunk.delta, 'content', None)
                    if text:
                        full_response += text
                        # Hi·ªÉn th·ªã con tr·ªè khi stream
                        message_placeholder.markdown(full_response + "‚ñå")

                # Ho√†n t·∫•t hi·ªÉn th·ªã
                message_placeholder.markdown(full_response)
                
                # C. L∆∞u c√¢u tr·∫£ l·ªùi c·ªßa Bot v√†o l·ªãch s·ª≠
                assistant_msg_obj = types.Content(role="model", parts=[types.Part(text=full_response)])
                st.session_state.gemini_messages.append(assistant_msg_obj)

            except Exception as e:
                # X·ª≠ l√Ω l·ªói hi·ªÉn th·ªã th√¢n thi·ªán
                error_msg = str(e)
                if "429" in error_msg:
                    st.error("H·ªá th·ªëng ƒëang b·∫≠n (Qu√° t·∫£i Quota). Vui l√≤ng ƒë·ª£i 1 ph√∫t.")
                elif "404" in error_msg:
                    st.error(f"L·ªói Model: Kh√¥ng t√¨m th·∫•y model gemini-2.5-flash-lite. H√£y ki·ªÉm tra l·∫°i t√™n model.")
                else:
                    st.error(f"ƒê√£ x·∫£y ra l·ªói: {e}")